{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_train = pd.read_csv('DailyDelhiClimateTrain.csv')\r\n",
    "df_test = pd.read_csv('DailyDelhiClimateTest.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date   meantemp   humidity  wind_speed  meanpressure\n",
       "0  2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
       "1  2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
       "2  2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
       "3  2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
       "4  2013-01-05   6.000000  86.833333    3.700000   1016.500000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dates = df_train['date'].values\r\n",
    "temp = df_train['meantemp'].values\r\n",
    "\r\n",
    "temp_test = df_test['meantemp'].values\r\n",
    "\r\n",
    "# plt.figure(figsize=(15,5))\r\n",
    "# plt.plot(dates, temp)\r\n",
    "# plt.title('Temperature average', fontsize=20)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\r\n",
    "    series = tf.expand_dims(series, axis=-1)\r\n",
    "    print(\"hasil tf.expand_dims\",series)\r\n",
    "\r\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\r\n",
    "    print(\"hasil tf.data.Dataset.from_tensor_slices\", ds.__str__())\r\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\r\n",
    "    print(\"hasil ds.window \",ds)\r\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\r\n",
    "    print(\"hasil ds.flat_map \",ds)\r\n",
    "    ds = ds.shuffle(shuffle_buffer)\r\n",
    "    print(\"hasil ds.shuffle \",ds)\r\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1:]))\r\n",
    "    print(\"hasil ds.map \", ds)\r\n",
    "    return ds.batch(batch_size).prefetch(1) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "temp[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([10.        ,  7.4       ,  7.16666667,  8.66666667,  6.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "train_set = windowed_dataset(temp, window_size=60, batch_size=100, shuffle_buffer=1000)\r\n",
    "test_set = windowed_dataset(temp_test, window_size=60, batch_size=100, shuffle_buffer=1000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hasil tf.expand_dims tf.Tensor(\n",
      "[[10.        ]\n",
      " [ 7.4       ]\n",
      " [ 7.16666667]\n",
      " ...\n",
      " [14.0952381 ]\n",
      " [15.05263158]\n",
      " [10.        ]], shape=(1462, 1), dtype=float64)\n",
      "hasil tf.data.Dataset.from_tensor_slices <TensorSliceDataset shapes: (1,), types: tf.float64>\n",
      "hasil ds.window  <WindowDataset shapes: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.float64, name=None), TensorShape([])), types: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.float64, name=None), TensorShape([]))>\n",
      "hasil ds.flat_map  <FlatMapDataset shapes: (None, 1), types: tf.float64>\n",
      "hasil ds.shuffle  <ShuffleDataset shapes: (None, 1), types: tf.float64>\n",
      "hasil ds.map  <MapDataset shapes: ((None, 1), (None, 1)), types: (tf.float64, tf.float64)>\n",
      "hasil tf.expand_dims tf.Tensor(\n",
      "[[15.91304348]\n",
      " [18.5       ]\n",
      " [17.11111111]\n",
      " [18.7       ]\n",
      " [18.38888889]\n",
      " [19.31818182]\n",
      " [14.70833333]\n",
      " [15.68421053]\n",
      " [14.57142857]\n",
      " [12.11111111]\n",
      " [11.        ]\n",
      " [11.78947368]\n",
      " [13.23529412]\n",
      " [13.2       ]\n",
      " [16.43478261]\n",
      " [14.65      ]\n",
      " [11.72222222]\n",
      " [13.04166667]\n",
      " [14.61904762]\n",
      " [15.26315789]\n",
      " [15.39130435]\n",
      " [18.44      ]\n",
      " [18.11764706]\n",
      " [18.34782609]\n",
      " [21.        ]\n",
      " [16.17857143]\n",
      " [16.5       ]\n",
      " [14.86363636]\n",
      " [15.66666667]\n",
      " [16.44444444]\n",
      " [16.125     ]\n",
      " [15.25      ]\n",
      " [17.09090909]\n",
      " [15.63636364]\n",
      " [18.7       ]\n",
      " [18.63157895]\n",
      " [16.88888889]\n",
      " [15.125     ]\n",
      " [15.7       ]\n",
      " [15.375     ]\n",
      " [14.66666667]\n",
      " [15.625     ]\n",
      " [16.25      ]\n",
      " [16.33333333]\n",
      " [16.875     ]\n",
      " [17.57142857]\n",
      " [20.25      ]\n",
      " [21.3       ]\n",
      " [21.125     ]\n",
      " [22.36363636]\n",
      " [23.375     ]\n",
      " [21.83333333]\n",
      " [19.125     ]\n",
      " [18.625     ]\n",
      " [19.125     ]\n",
      " [19.        ]\n",
      " [18.75      ]\n",
      " [19.875     ]\n",
      " [23.33333333]\n",
      " [24.46153846]\n",
      " [23.75      ]\n",
      " [20.5       ]\n",
      " [19.125     ]\n",
      " [19.75      ]\n",
      " [20.        ]\n",
      " [22.625     ]\n",
      " [21.54545455]\n",
      " [20.78571429]\n",
      " [19.9375    ]\n",
      " [18.53333333]\n",
      " [17.375     ]\n",
      " [17.44444444]\n",
      " [18.        ]\n",
      " [19.875     ]\n",
      " [24.        ]\n",
      " [20.9       ]\n",
      " [24.69230769]\n",
      " [24.66666667]\n",
      " [23.33333333]\n",
      " [25.        ]\n",
      " [27.25      ]\n",
      " [28.        ]\n",
      " [28.91666667]\n",
      " [26.5       ]\n",
      " [29.1       ]\n",
      " [29.5       ]\n",
      " [29.88888889]\n",
      " [31.        ]\n",
      " [29.28571429]\n",
      " [30.625     ]\n",
      " [31.375     ]\n",
      " [29.75      ]\n",
      " [30.5       ]\n",
      " [30.93333333]\n",
      " [29.23076923]\n",
      " [31.22222222]\n",
      " [27.        ]\n",
      " [25.625     ]\n",
      " [27.125     ]\n",
      " [27.85714286]\n",
      " [29.25      ]\n",
      " [29.25      ]\n",
      " [29.66666667]\n",
      " [30.5       ]\n",
      " [31.22222222]\n",
      " [31.        ]\n",
      " [32.55555556]\n",
      " [34.        ]\n",
      " [33.5       ]\n",
      " [34.5       ]\n",
      " [34.25      ]\n",
      " [32.9       ]\n",
      " [32.875     ]\n",
      " [32.        ]], shape=(114, 1), dtype=float64)\n",
      "hasil tf.data.Dataset.from_tensor_slices <TensorSliceDataset shapes: (1,), types: tf.float64>\n",
      "hasil ds.window  <WindowDataset shapes: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.float64, name=None), TensorShape([])), types: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.float64, name=None), TensorShape([]))>\n",
      "hasil ds.flat_map  <FlatMapDataset shapes: (None, 1), types: tf.float64>\n",
      "hasil ds.shuffle  <ShuffleDataset shapes: (None, 1), types: tf.float64>\n",
      "hasil ds.map  <MapDataset shapes: ((None, 1), (None, 1)), types: (tf.float64, tf.float64)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "model = tf.keras.models.Sequential([\r\n",
    "    tf.keras.layers.LSTM(60, return_sequences=True),\r\n",
    "    tf.keras.layers.LSTM(60),\r\n",
    "    tf.keras.layers.Dense(30, activation = 'relu'),\r\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1),\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)\r\n",
    "model.compile(loss=tf.keras.losses.Huber(),\r\n",
    "optimizer=optimizer,\r\n",
    "metrics=['mae'])\r\n",
    "\r\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 153ms/step - loss: 24.4640 - mae: 24.9640 - val_loss: 25.6029 - val_mae: 26.1029\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 1s 77ms/step - loss: 24.4356 - mae: 24.9356 - val_loss: 25.5893 - val_mae: 26.0893\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 1s 85ms/step - loss: 24.7829 - mae: 25.2829 - val_loss: 25.5746 - val_mae: 26.0746\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 1s 82ms/step - loss: 24.7209 - mae: 25.2209 - val_loss: 25.5597 - val_mae: 26.0597\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 1s 83ms/step - loss: 24.5278 - mae: 25.0278 - val_loss: 25.5447 - val_mae: 26.0447\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 1s 79ms/step - loss: 24.5319 - mae: 25.0319 - val_loss: 25.5297 - val_mae: 26.0297\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 1s 79ms/step - loss: 24.3793 - mae: 24.8793 - val_loss: 25.5147 - val_mae: 26.0147\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 1s 85ms/step - loss: 24.3956 - mae: 24.8956 - val_loss: 25.4997 - val_mae: 25.9997\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 24.3132 - mae: 24.8132 - val_loss: 25.4847 - val_mae: 25.9847\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 1s 78ms/step - loss: 24.2729 - mae: 24.7729 - val_loss: 25.4697 - val_mae: 25.9697\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.4617 - mae: 24.9617 - val_loss: 25.4547 - val_mae: 25.9547\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.4686 - mae: 24.9686 - val_loss: 25.4397 - val_mae: 25.9397\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.4896 - mae: 24.9896 - val_loss: 25.4247 - val_mae: 25.9247\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 1s 77ms/step - loss: 24.4414 - mae: 24.9414 - val_loss: 25.4097 - val_mae: 25.9097\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.3182 - mae: 24.8182 - val_loss: 25.3947 - val_mae: 25.8947\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 1s 80ms/step - loss: 24.3529 - mae: 24.8529 - val_loss: 25.3797 - val_mae: 25.8797\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.3341 - mae: 24.8341 - val_loss: 25.3647 - val_mae: 25.8647\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 24.3211 - mae: 24.8211 - val_loss: 25.3497 - val_mae: 25.8497\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.4310 - mae: 24.9310 - val_loss: 25.3347 - val_mae: 25.8347\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.1998 - mae: 24.6998 - val_loss: 25.3197 - val_mae: 25.8197\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 1s 77ms/step - loss: 24.3545 - mae: 24.8545 - val_loss: 25.3047 - val_mae: 25.8047\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.2517 - mae: 24.7517 - val_loss: 25.2897 - val_mae: 25.7897\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 24.2291 - mae: 24.7291 - val_loss: 25.2747 - val_mae: 25.7747\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 24.4521 - mae: 24.9521 - val_loss: 25.2597 - val_mae: 25.7597\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 24.5371 - mae: 25.0371 - val_loss: 25.2447 - val_mae: 25.7447\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 24.1060 - mae: 24.6060 - val_loss: 25.2297 - val_mae: 25.7297\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 1s 78ms/step - loss: 24.1589 - mae: 24.6589 - val_loss: 25.2147 - val_mae: 25.7147\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 1s 82ms/step - loss: 24.2355 - mae: 24.7355 - val_loss: 25.1997 - val_mae: 25.6997\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 24.0492 - mae: 24.5492 - val_loss: 25.1847 - val_mae: 25.6847\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 24.1249 - mae: 24.6249 - val_loss: 25.1697 - val_mae: 25.6697\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 1s 81ms/step - loss: 23.9644 - mae: 24.4644 - val_loss: 25.1547 - val_mae: 25.6547\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 24.2889 - mae: 24.7889 - val_loss: 25.1397 - val_mae: 25.6397\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 1s 82ms/step - loss: 24.3125 - mae: 24.8125 - val_loss: 25.1247 - val_mae: 25.6247\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 1s 78ms/step - loss: 24.2967 - mae: 24.7967 - val_loss: 25.1097 - val_mae: 25.6097\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 23.9376 - mae: 24.4376 - val_loss: 25.0947 - val_mae: 25.5947\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 23.8632 - mae: 24.3632 - val_loss: 25.0797 - val_mae: 25.5797\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 24.1894 - mae: 24.6894 - val_loss: 25.0647 - val_mae: 25.5647\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 24.1377 - mae: 24.6377 - val_loss: 25.0497 - val_mae: 25.5497\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 23.9906 - mae: 24.4906 - val_loss: 25.0347 - val_mae: 25.5347\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 24.0022 - mae: 24.5022 - val_loss: 25.0197 - val_mae: 25.5197\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 24.1061 - mae: 24.6061 - val_loss: 25.0047 - val_mae: 25.5047\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 24.1892 - mae: 24.6892 - val_loss: 24.9897 - val_mae: 25.4897\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 1s 83ms/step - loss: 23.7521 - mae: 24.2521 - val_loss: 24.9747 - val_mae: 25.4747\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 23.8107 - mae: 24.3107 - val_loss: 24.9597 - val_mae: 25.4597\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 24.0249 - mae: 24.5249 - val_loss: 24.9447 - val_mae: 25.4447\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 23.8676 - mae: 24.3676 - val_loss: 24.9297 - val_mae: 25.4297\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 24.1258 - mae: 24.6258 - val_loss: 24.9147 - val_mae: 25.4147\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 23.9607 - mae: 24.4607 - val_loss: 24.8997 - val_mae: 25.3997\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 23.9468 - mae: 24.4468 - val_loss: 24.8847 - val_mae: 25.3847\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 1s 77ms/step - loss: 24.2624 - mae: 24.7624 - val_loss: 24.8697 - val_mae: 25.3697\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "mat = tf.zeros([3,4]) # buat array tiga dimensi, di mana \r\n",
    "# dimensi 1 ada dua buah array, d 2 ada 3 buah array, d4 ada 4 buah array\r\n",
    "mat_exp = tf.expand_dims(tf.zeros([3,4]), axis=-1) # mengexpand dimensi dari array input\r\n",
    "# sebanyak satu dimensi, axis menentukan di mana dimensi tambahan itu ditambahkan\r\n",
    "# axis=-1 menambah dimensi di dimensi terakhir\r\n",
    "# axis = 0 menambah dimensi di dimensi awal\r\n",
    "# axis = 1 menambah dimensi di dimensi kedua\r\n",
    "x = [y for y in range(1,11)]\r\n",
    "new_x = tf.expand_dims(x, axis=-1)\r\n",
    "test = tf.data.Dataset.from_tensor_slices(new_x)\r\n",
    "test = test.window(4 + 1, shift=1, drop_remainder=True)\r\n",
    "test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<WindowDataset shapes: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.int32, name=None), TensorShape([])), types: DatasetSpec(TensorSpec(shape=(1,), dtype=tf.int32, name=None), TensorShape([]))>"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "mat_exp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(mat_exp)\r\n",
    "ds = ds.window()\r\n",
    "for window in ds:\r\n",
    "    print(list(window.as_numpy_iterator()))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "window() missing 1 required positional argument: 'size'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-2200e45074b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_exp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: window() missing 1 required positional argument: 'size'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, shift=2,\r\n",
    "                                        drop_remainder=True)\r\n",
    "for window in dataset:\r\n",
    "    print(list(window.as_numpy_iterator()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2]\n",
      "[2, 3, 4]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\r\n",
    "import numpy as np\r\n",
    "data = np.array([[i] for i in range(50)])\r\n",
    "targets = np.array([[i] for i in range(50)])\r\n",
    "data_gen = TimeseriesGenerator(data, targets,\r\n",
    "                               length=10, sampling_rate=2,\r\n",
    "                               batch_size=2)\r\n",
    "assert len(data_gen) == 20\r\n",
    "batch_0 = data_gen[0]\r\n",
    "x, y = batch_0\r\n",
    "assert np.array_equal(x,\r\n",
    "                      np.array([[[0], [2], [4], [6], [8]],\r\n",
    "                                [[1], [3], [5], [7], [9]]]))\r\n",
    "assert np.array_equal(y,\r\n",
    "                      np.array([[10], [11]]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'slice'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3e2188310375>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 self.start_index, self.end_index + 1, size=self.batch_size)\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             rows = np.arange(i, min(i + self.batch_size *\n\u001b[0;32m    370\u001b[0m                                     self.stride, self.end_index + 1), self.stride)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'slice'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}